{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Pretrained BERT on AzureML\n",
    "This notebook contains an end-to-end walkthrough of using Azure Machine Learning Service to run [Google's TensorFlow repository for the BERT model](https://github.com/google-research/bert).\n",
    "\n",
    "You will find the following contents:\n",
    "- Download pretrained TensorFlow BERT checkpoint and GLUE dataset on the remote compute and store them in Azure storage\n",
    "- Speep-up fine-tuning BERT for GLUE dataset on AzureML GPU clusters\n",
    "- Further fine-tune BERT wtih AzureML hyperparameter optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning (AML)\n",
    "* If you are running in your own environment, follow [SDK installation instructions](https://docs.microsoft.com/azure/machine-learning/service/how-to-configure-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "\n",
    "To create or access an Azure ML Workspace, you will need to import the AML library and the following information:\n",
    "* A name for your workspace\n",
    "* Your subscription id\n",
    "* The resource group name\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step or create a new one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "workspace_name = \"\"\n",
    "subscription_id = \"\"\n",
    "resource_group_name = \"\"\n",
    "location = \"\"\n",
    "\n",
    "ws = Workspace._get_or_create(workspace_name,\n",
    "                             subscription_id=subscription_id,\n",
    "                             resource_group=resource_group_name,\n",
    "                             location=location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Model and GLUE dataset on the remote compute\n",
    "\n",
    "We will download the model and store it in an Azure Blob container. We will also download the [GLUE data](https://gluebenchmark.com/tasks) by running the [script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e) and unpack it to the same Azure Blob container.\n",
    "\n",
    "All of the above steps will be done in a remote AzureML cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a project directory\n",
    "Create a directory that will contain all the necessary code from your local machine that you will need access to on the remote resource. This includes the training script and any additional files your training script depends on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project_folder = './bert'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a local clone of the original repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('git clone https://github.com/google-research/bert.git')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have prepared a python script [download_model_and_dataset.py](download_model_and_dataset.py) to do the following tasks:\n",
    "- Download [the pre-trained models released by Google](https://github.com/google-research/bert#pre-trained-models) to local directory\n",
    "- Dump model and its metadata into a mounted Azure Blob container\n",
    "- Run the [script](https://gist.github.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e) to download the [GLUE data](https://gluebenchmark.com/tasks) in the mounted Azure Blob container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.copy('download_model_and_dataset.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define AzureML datastore to collect converted model file\n",
    "\n",
    "To make data accessible for remote training, AML provides a convenient way to do so via a [Datastore](https://docs.microsoft.com/azure/machine-learning/service/how-to-access-data). The datastore provides a mechanism for you to upload/download data to Azure Storage, and interact with it from your remote compute targets.\n",
    "\n",
    "Each workspace is associated with a default Azure Blob datastore named `'workspaceblobstore'`. In this work, we use this default datastore to collect the converted model file and the GLUE training dataset ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "ds = Datastore(ws, 'workspaceblobstore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an experiment\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) to track all the runs in your workspace for this tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'BERT_TF'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Tensorflow estimator\n",
    "The AML SDK's Tensorflow estimator enables you to easily submit Tensorflow training jobs for both single-node and distributed runs. For more information on the Tensorflow estimator, refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-train-tensorflow). The entry script `download_model_and_dataset.py` takes model name variable:\n",
    "\n",
    "- BERT-Base, Uncased: 12-layer: `uncased_L-12_H-768_A-12`\n",
    "- BERT-Large, Uncased: `uncased_L-24_H-1024_A-16`\n",
    "- BERT-Base, Cased: `cased_L-12_H-768_A-12`\n",
    "- BERT-Base, Multilingual: `multilingual_L-12_H-768_A-12`\n",
    "- BERT-Base, Chinese: `chinese_L-12_H-768_A-12`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "script_params = {\n",
    "    '--bert_model_name': 'uncased_L-12_H-768_A-12',\n",
    "    '--model_dump_path': ds.path('BERT_model/uncased_L-12_H-768_A-12').as_mount(),\n",
    "    '--glue_data_path': ds.path('glue_data_path').as_mount()\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(source_directory=project_folder,\n",
    "                    vm_size='STANDARD_D2_v2',\n",
    "                    script_params=script_params,\n",
    "                    entry_script='download_model_and_dataset.py',\n",
    "                    node_count=1,\n",
    "                    use_gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code defines a CPU cluster with `vm_size` of `STANDARD_D2_V2`. We do not need GPU cluster for data movement tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and Monitor your run\n",
    "Run your experiment by submitting your estimator object. The widget is asynchronous and provides live updates every 10-15 seconds until the job completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(estimator)\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning with BERT and GLUE dataset\n",
    "As our `BERT` model and `GLUE` dataset are ready in Azure storage, we can start to fine-tune the model on a single node using a GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Tensorflow estimator for fine-tuning\n",
    "Let us create a new Tensorflow estimator to run the fine-tuning script `run_classifier.py`, that is already provided at [the original repository](https://github.com/google-research/bert/blob/master/run_classifier.py). Please refer [here](https://github.com/google-research/bert#sentence-and-sentence-pair-classification-tasks) for more detail about the script. A `STANDARD_NC6` vm_size is used, which has 1 GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "ft_estimator = TensorFlow(source_directory=project_folder,\n",
    "                    vm_size='STANDARD_NC6',\n",
    "                    script_params = {\n",
    "                          '--task_name': 'MRPC',\n",
    "                          '--do_train' : True,\n",
    "                          '--do_eval': True,\n",
    "                          '--data_dir': ds.path('glue_data_path/MRPC/').as_mount(),\n",
    "                          '--vocab_file': ds.path('BERT_model/uncased_L-12_H-768_A-12/vocab.txt').as_mount(),\n",
    "                          '--bert_config_file': ds.path('BERT_model/uncased_L-12_H-768_A-12/bert_config.json').as_mount(),\n",
    "                          '--init_checkpoint': ds.path('BERT_model/uncased_L-12_H-768_A-12/bert_model.ckpt').as_mount(),\n",
    "                          '--max_seq_length': 128,\n",
    "                          '--train_batch_size': 32,\n",
    "                          '--learning_rate': 2e-5,\n",
    "                          '--num_train_epochs': 3.0,\n",
    "                          '--output_dir': './outputs'\n",
    "                    },\n",
    "                    entry_script='run_classifier.py',\n",
    "                    use_gpu=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit and Monitor your run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(ft_estimator)\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-Tuning BERT with Hyperparameter Tuning\n",
    "\n",
    "We would also like to optimize our hyperparameter, `learning rate`, using Azure Machine Learning's hyperparameter tuning capabilities.\n",
    "\n",
    "To use AML's tracking and metrics capabilities, we need to add a small amount of AzureML code inside the training script.\n",
    "\n",
    "In `run_classifier.py`, we will log some metrics to our AML run. To do so, we will access the AML run object within the script:\n",
    "```Python\n",
    "from azureml.core.run import Run\n",
    "run = Run.get_context()\n",
    "```\n",
    "Further within `run_classifier.py`, we log the learning rate, and the epoch training and eval loss the model achieves:\n",
    "```Python\n",
    "run.log('lr', np.float(args.learning_rate))\n",
    "\n",
    "run.log('train_mean_loss', mean_loss)\n",
    "run.log('eval_mean_loss', mean_loss)\n",
    "run.log('train_example_loss', mean_loss)\n",
    "run.log('eval_example_loss', mean_loss)\n",
    "```\n",
    "These run metrics will become particularly important when we begin hyperparameter tuning our model in the \"Tune model hyperparameters\" section.\n",
    "\n",
    "Let's first copy the modified [run_classifier.py](./run_classifier.py) into our local project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.copy('run_classifier.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a hyperparameter sweep\n",
    "First, we will define the hyperparameter space to sweep over. In this example we will use random sampling to try different configuration sets of hyperparameter to maximize our primary metric, the mean training loss (`train_mean_loss`).  We specify a `loguniform` distribution for the learning rate parameter since we want to evenly space the samples over a range that varies by a few orders of magnitude, ~1e-4 to ~1e-6.\n",
    "\n",
    "Then, we specify the early termination policy to use to early terminate poorly performing runs. Here we use the `BanditPolicy`, which will terminate any run that doesn't fall within the slack factor of our primary evaluation metric. In this tutorial, we will apply this policy every epoch (since we report our `train_mean_loss` metric every epoch and `evaluation_interval=1`). \n",
    "Refer [here](https://docs.microsoft.com/azure/machine-learning/service/how-to-tune-hyperparameters#specify-an-early-termination-policy) for more information on the BanditPolicy and other policies available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "param_sampling = RandomParameterSampling( {\n",
    "        'learning_rate': loguniform(-9, -14),\n",
    "    }\n",
    ")\n",
    "\n",
    "policy = BanditPolicy(delay_evaluation=25, evaluation_interval=1, slack_amount=0.10)\n",
    "\n",
    "hyperdrive_run_config = HyperDriveRunConfig(estimator=ft_estimator,\n",
    "                                            hyperparameter_sampling=param_sampling, \n",
    "                                            primary_metric_name='train_mean_loss',\n",
    "                                            primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "                                            policy=policy,\n",
    "                                            max_total_runs=8,\n",
    "                                            max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lauch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run = experiment.submit(hyperdrive_run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor HyperDrive runs\n",
    "We can monitor the progress of the runs with the following Jupyter widget. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and register the best model\n",
    "Once all the runs complete, we can find the run that produced the model with the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print(best_run)\n",
    "print('Best Run is:\\n  Validation accuracy: {0:.5f} \\n  Validation loss: {1:.5f} \\n  Learning rate: {2:.8f}'.format(\n",
    "        best_run_metrics['eval_accuracy'],\n",
    "        best_run_metrics['loss'],\n",
    "        best_run_metrics['lr']\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the resulting optimal `learning_rate` with the value suggested by the [original implementation hyper-parameters](https://github.com/google-research/bert#sentence-and-sentence-pair-classification-tasks): 2e-5\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "minxia"
   }
  ],
  "kernelspec": {
   "display_name": "candidate_env",
   "language": "python",
   "name": "candidate_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
